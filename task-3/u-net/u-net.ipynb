{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.pardir, os.pardir))\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.transforms.functional as F_transforms\n",
    "import torchinfo\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "#from amlutils.task3 import load_zipped_pickle, visualize_segmentation\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "pl.seed_everything(RANDOM_SEED, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE DIRECTORY\n",
    "data_dir = os.path.join(os.pardir, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object\n",
    "\n",
    "def visualize_segmentation(ax, image, segmentation, segmentation_opacity=0.5):\n",
    "    ax.imshow(image)\n",
    "    ax.imshow(segmentation, alpha=segmentation_opacity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_concat(conv_out, upconv_out):\n",
    "    '''\n",
    "    Perform\n",
    "    '''\n",
    "    conv_out_crop = F_transforms.center_crop(conv_out, upconv_out.shape[2:])\n",
    "    return torch.concat([conv_out_crop, upconv_out], dim=1) \n",
    "\n",
    "def print_shape(var_name: str, var):\n",
    "    pass\n",
    "    #print(f'{var_name}.shape = {var.shape}')\n",
    "\n",
    "def get_num_incoming_nodes(tensor):\n",
    "    channels, _, width, height = tensor.shape\n",
    "    return channels * width * height\n",
    "\n",
    "def initialize_conv_weights(weights):\n",
    "    std = math.sqrt(2 / get_num_incoming_nodes(weights))\n",
    "    nn.init.normal_(weights, mean=0.0, std=std)\n",
    "\n",
    "def initialize_conv_bias(bias):\n",
    "    nn.init.zeros_(bias)\n",
    "\n",
    "def initialize_conv_relu_layer(layer):\n",
    "    for name, param in layer.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            initialize_conv_weights(param.data)\n",
    "        if 'bias' in name:\n",
    "            initialize_conv_bias(param.data)\n",
    "\n",
    "class UNet(pl.LightningModule):\n",
    "    '''\n",
    "    Architecture based on research paper:\n",
    "\n",
    "    https://arxiv.org/pdf/1505.04597.pdf\n",
    "    '''\n",
    "\n",
    "    def __init__(self, n_classes=2):\n",
    "        '''\n",
    "        Initialize layers.\n",
    "        \n",
    "        Args:\n",
    "            n_classes (int): Number of classes to map to (default=2).\n",
    "        '''\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        ## Contracting path. ##\n",
    "        self.contract_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.contract_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.contract_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.contract_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.contract_conv4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.contract_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.contract_conv5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.contract_conv6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.contract_pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.contract_conv7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.contract_conv8 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.contract_pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.contract_conv9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.contract_conv10 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.contract_dropout = nn.Dropout(0.1)\n",
    "\n",
    "        ## Expansive path. ##\n",
    "        self.expand_upconv1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(1024, 512, kernel_size=2)\n",
    "        )\n",
    "        self.expand_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 512, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.expand_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.expand_upconv2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(512, 256, kernel_size=2)\n",
    "        )\n",
    "        self.expand_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.expand_conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.expand_upconv3 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(256, 128, kernel_size=2)\n",
    "        )\n",
    "        self.expand_conv5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.expand_conv6 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.expand_upconv4 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, kernel_size=2)\n",
    "        )\n",
    "        self.expand_conv7 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.expand_conv8 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.expand_final_conv = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if name.endswith(\".weight\"):\n",
    "                initialize_conv_weights(param.data)\n",
    "            if name.endswith(\".bias\"):\n",
    "                initialize_conv_bias(param.data)\n",
    "\n",
    "    def forward(self, X):\n",
    "        ## Contracting path. ##\n",
    "        print_shape('X', X)\n",
    "        contract_conv1_out = self.contract_conv1(X)\n",
    "        print_shape('contract_conv1_out', contract_conv1_out)\n",
    "        contract_conv2_out = self.contract_conv2(contract_conv1_out)\n",
    "        print_shape('contract_conv2_out', contract_conv2_out)\n",
    "        contract_pool1_out = self.contract_pool1(contract_conv2_out)\n",
    "        print_shape('contract_pool1_out', contract_pool1_out)\n",
    "\n",
    "        contract_conv3_out = self.contract_conv3(contract_pool1_out)\n",
    "        print_shape('contract_conv3_out', contract_conv3_out)\n",
    "        contract_conv4_out = self.contract_conv4(contract_conv3_out)\n",
    "        print_shape('contract_conv4_out', contract_conv4_out)\n",
    "        contract_pool2_out = self.contract_pool2(contract_conv4_out)\n",
    "        print_shape('contract_pool2_out', contract_pool2_out)\n",
    "\n",
    "        contract_conv5_out = self.contract_conv5(contract_pool2_out)\n",
    "        print_shape('contract_conv5_out', contract_conv5_out)\n",
    "        contract_conv6_out = self.contract_conv6(contract_conv5_out)\n",
    "        print_shape('contract_conv6_out', contract_conv6_out)\n",
    "        contract_pool3_out = self.contract_pool3(contract_conv6_out)\n",
    "        print_shape('contract_pool3_out', contract_pool3_out)\n",
    "\n",
    "        contract_conv7_out = self.contract_conv7(contract_pool3_out)\n",
    "        print_shape('contract_conv7_out', contract_conv7_out)\n",
    "        contract_conv8_out = self.contract_conv8(contract_conv7_out)\n",
    "        print_shape('contract_conv8_out', contract_conv8_out)\n",
    "        contract_pool4_out = self.contract_pool4(contract_conv8_out)\n",
    "        print_shape('contract_pool4_out', contract_pool4_out)\n",
    "\n",
    "        contract_conv9_out = self.contract_conv9(contract_pool4_out)\n",
    "        print_shape('contract_conv9_out', contract_conv9_out)\n",
    "        contract_conv10_out = self.contract_conv10(contract_conv9_out)\n",
    "        print_shape('contract_conv10_out', contract_conv10_out)\n",
    "\n",
    "        contract_dropout_out = self.contract_dropout(contract_conv10_out)\n",
    "        print_shape('contract_dropout_out', contract_dropout_out)\n",
    "\n",
    "        ## Expansive path. ##\n",
    "        expand_upconv1_out = self.expand_upconv1(contract_dropout_out)\n",
    "        print_shape('expand_upconv1_out', expand_upconv1_out)\n",
    "        expand_conv1_in = crop_and_concat(contract_conv8_out, expand_upconv1_out)\n",
    "        print_shape('expand_conv1_in', expand_conv1_in)\n",
    "        expand_conv1_out = self.expand_conv1(expand_conv1_in)\n",
    "        print_shape('expand_conv1_out', expand_conv1_out)\n",
    "        expand_conv2_out = self.expand_conv2(expand_conv1_out)\n",
    "        print_shape('expand_conv2_out', expand_conv2_out)\n",
    "\n",
    "        expand_upconv2_out = self.expand_upconv2(expand_conv2_out)\n",
    "        print_shape('expand_upconv2_out', expand_upconv2_out)\n",
    "        expand_conv3_in = crop_and_concat(contract_conv6_out, expand_upconv2_out)\n",
    "        print_shape('expand_conv3_in', expand_conv3_in)\n",
    "        expand_conv3_out = self.expand_conv3(expand_conv3_in)\n",
    "        print_shape('expand_conv3_out', expand_conv3_out)\n",
    "        expand_conv4_out = self.expand_conv4(expand_conv3_out)\n",
    "        print_shape('expand_conv4_out', expand_conv4_out)\n",
    "\n",
    "        expand_upconv3_out = self.expand_upconv3(expand_conv4_out)\n",
    "        print_shape('expand_upconv3_out', expand_upconv3_out)\n",
    "        expand_conv5_in = crop_and_concat(contract_conv4_out, expand_upconv3_out)\n",
    "        print_shape('expand_conv5_in', expand_conv5_in)\n",
    "        expand_conv5_out = self.expand_conv5(expand_conv5_in)\n",
    "        print_shape('expand_conv5_out', expand_conv5_out)\n",
    "        expand_conv6_out = self.expand_conv6(expand_conv5_out)\n",
    "        print_shape('expand_conv6_out', expand_conv6_out)\n",
    "\n",
    "        expand_upconv4_out = self.expand_upconv4(expand_conv6_out)\n",
    "        print_shape('expand_upconv4_out', expand_upconv4_out)\n",
    "        expand_conv7_in = crop_and_concat(contract_conv2_out, expand_upconv4_out)\n",
    "        print_shape('expand_conv7_in', expand_conv7_in)\n",
    "        expand_conv7_out = self.expand_conv7(expand_conv7_in)\n",
    "        print_shape('expand_conv7_out', expand_conv7_out)\n",
    "        expand_conv8_out = self.expand_conv8(expand_conv7_out)\n",
    "        print_shape('expand_conv8_out', expand_conv8_out)\n",
    "\n",
    "        final_out = self.expand_final_conv(expand_conv8_out)\n",
    "        print_shape('final_out', final_out)\n",
    "\n",
    "        return final_out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        X, y = batch\n",
    "        X = torch.unsqueeze(X, 1)\n",
    "\n",
    "        y_hat = self.forward(X)\n",
    "        y = F_transforms.center_crop(y, y_hat.shape[2:])\n",
    "\n",
    "        '''\n",
    "        prediction = F.softmax(y_hat, dim=1)\n",
    "        prediction = torch.squeeze(prediction)\n",
    "\n",
    "        X_crop = F_transforms.center_crop(X, y_hat.shape[2:])\n",
    "        X_crop = torch.squeeze(X_crop)\n",
    "        X_crop = torch.squeeze(X_crop).numpy()\n",
    "\n",
    "        visualize_segmentation(\n",
    "            X_crop,\n",
    "            prediction[0,:,:].detach().numpy(),\n",
    "            segmentation_opacity=1\n",
    "        )\n",
    "\n",
    "        visualize_segmentation(\n",
    "            X_crop,\n",
    "            prediction[1,:,:].detach().numpy(),\n",
    "            segmentation_opacity=1\n",
    "        )\n",
    "        '''\n",
    "\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        self.log('train_loss', loss)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    #def validation_step(self, batch, batch_nb):\n",
    "    #    x, y = batch\n",
    "    #    y_hat = self.forward(x)\n",
    "    #    loss = F.cross_entropy(y_hat, y)\n",
    "    #    return {'val_loss': loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = load_zipped_pickle(os.path.join(data_dir, 'labeled-images.pkl'))\n",
    "\n",
    "X_train = train_set[0]['Image']\n",
    "y_train = train_set[0]['Label']\n",
    "\n",
    "def convert_to_tensor(X, data_type=torch.float):\n",
    "    X_tensor = torch.tensor(X, dtype=data_type)\n",
    "    # Unsqueeze X tensor to have another dimension representing the channel, this\n",
    "    # is needed for convolutions.\n",
    "    X_tensor = torch.unsqueeze(X_tensor, 0)\n",
    "    return X_tensor\n",
    "\n",
    "def build_data_loader(X, y):\n",
    "    X_tensor = convert_to_tensor(X)\n",
    "    print(f'[build_data_loader] X_tensor.shape = {X_tensor.shape}')\n",
    "    y_tensor = convert_to_tensor(y, torch.long)\n",
    "\n",
    "    train_tensor = TensorDataset(X_tensor, y_tensor)\n",
    "    return DataLoader(dataset=train_tensor, batch_size=1, shuffle=True)\n",
    "\n",
    "train_loader = build_data_loader(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_segmenter = UNet()\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='train_loss',\n",
    "    stopping_threshold=0.001,\n",
    "    patience=100\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[early_stopping],\n",
    "    deterministic=True\n",
    ")\n",
    "trainer.fit(mv_segmenter, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint('mv-segmenter-u-net-loss-threshold-0.001.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_relu = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=3, padding='same'),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "for name, param in conv_relu.named_parameters():\n",
    "    print(f'{name}: {param}')\n",
    "\n",
    "def get_num_incoming_nodes(tensor):\n",
    "    channels, _, width, height = tensor.shape\n",
    "    return channels * width * height\n",
    "\n",
    "def initialize_conv_weights(weights):\n",
    "    std = math.sqrt(2 / get_num_incoming_nodes(weights))\n",
    "    nn.init.normal_(weights, mean=0.0, std=std)\n",
    "\n",
    "def initialize_conv_bias(bias):\n",
    "    nn.init.zeros_(bias)\n",
    "\n",
    "def initialize_conv_relu_layer(layer):\n",
    "    for name, param in layer.named_parameters():\n",
    "        if name.endswith(\".weight\"):\n",
    "            initialize_conv_weights(param.data)\n",
    "        if name.endswith(\".bias\"):\n",
    "            initialize_conv_bias(param.data)\n",
    "\n",
    "initialize_conv_relu_layer(conv_relu)\n",
    "\n",
    "for name, param in conv_relu.named_parameters():\n",
    "    print(f'{name}: {param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float('inf') * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = convert_to_tensor(train_set[0]['Image'])\n",
    "image = torch.unsqueeze(image, 0)\n",
    "segmentation = mv_segmenter(image)\n",
    "segmentation = torch.squeeze(segmentation)\n",
    "segmentation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = F.softmax(segmentation, dim=0)\n",
    "print(prediction.shape)\n",
    "prediction = torch.max(prediction, dim=0).indices\n",
    "prediction = torch.squeeze(prediction)#.detach().numpy()\n",
    "#prediction = prediction[0,:,:].detach().numpy()\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = F.softmax(segmentation, dim=0)\n",
    "print(torch.min(prediction[0,:,:]))\n",
    "prediction = torch.round(prediction[1,:,:]).detach().numpy()\n",
    "np.max(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = F.softmax(segmentation, dim=0)\n",
    "prediction = torch.where(prediction[1,:,:] > 0.29, torch.ones(prediction.shape[1:]), torch.zeros(prediction.shape[1:])).numpy()\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "cropped_image = F_transforms.center_crop(image, prediction.shape[1:])\n",
    "cropped_label = F_transforms.center_crop(torch.tensor(train_set[0]['Label']), prediction.shape[1:]).numpy()\n",
    "cropped_image = torch.squeeze(cropped_image)\n",
    "cropped_image = torch.squeeze(cropped_image).numpy()\n",
    "\n",
    "visualize_segmentation(ax[0], cropped_image, prediction, segmentation_opacity=0.5)\n",
    "ax[0].set_title('U-Net Predicted Segmentation (P[Is MV]>0.29)')\n",
    "\n",
    "visualize_segmentation(ax[1], cropped_image, cropped_label, segmentation_opacity=0.5)\n",
    "ax[1].set_title('Ground Truth')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = load_zipped_pickle(os.path.join(data_dir, 'labeled-images.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_segmentation(train_set[0]['Image'], train_set[0]['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = torch.from_numpy(train_set[0]['Image'])\n",
    "train_input = torch.unsqueeze(train_input, 0)\n",
    "torchinfo.summary(UNet(), input_size=(1, *train_input.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_segmentation(\n",
    "    F_transforms.center_crop(torch.from_numpy(train_set[0]['Image']), prediction.shape).numpy(),\n",
    "    F_transforms.center_crop(torch.from_numpy(train_set[0]['Label']), prediction.shape).numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tens = F_transforms.center_crop(torch.from_numpy(train_set[0]['Image']), (60, 60))\n",
    "#torch.stack([tens, tens], dim=2).shape\n",
    "tens = torch.unsqueeze(tens, dim=2)\n",
    "torch.concat([tens, tens], dim=2).shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
