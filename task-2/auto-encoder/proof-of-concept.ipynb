{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Encoder Proof-Of-Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "sys.path.append(os.path.join(os.pardir, os.pardir))\n",
    "from amlutils.task2.loading import load_train_set\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_train_set(os.path.join(os.pardir, 'data'))\n",
    "\n",
    "display(X_train)\n",
    "\n",
    "#X_train = X_train.fillna(0.0)\n",
    "# Small hack, want that each signal is betweeb -1 and 1, so need to make\n",
    "# signals the features and transform, then switch back.\n",
    "X_train_scaled = X_train.T\n",
    "X_train_scaled.values[:] = MinMaxScaler(feature_range=(-1,1)).fit_transform(X_train_scaled)\n",
    "X_train_scaled = X_train_scaled.T\n",
    "\n",
    "X_train = X_train.fillna(0.0)\n",
    "X_train_scaled = X_train_scaled.fillna(0.0)\n",
    "\n",
    "display(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original with auto-encoded signal.\n",
    "num_rows = 1\n",
    "num_cols = 1\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(12 * num_cols,6 * num_rows))\n",
    "\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "axs.plot(list(range(17842)), X_train_scaled.iloc[0])\n",
    "axs.set(xlabel='Time', ylabel='Signal', title='Class 0 Sample')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_scaled.values, dtype=torch.float)\n",
    "# Unsqueeze X tensor to have another dimension representing the channel, this\n",
    "# is needed for convolutions.\n",
    "X_train_tensor = torch.unsqueeze(X_train_tensor, 1)\n",
    "y_train_tensor = torch.tensor(y_train.values)\n",
    "\n",
    "train_tensor = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(dataset=train_tensor, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "def conv1d_out_dim(in_dim, kernel_size, stride, padding=0, dilation=1):\n",
    "    return floor(float(in_dim + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)\n",
    "\n",
    "def maxpool1d_out_dim(in_dim, kernel_size, stride, padding=0, dilation=1):\n",
    "    return floor(float(in_dim + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)\n",
    "\n",
    "def convtranspose1d_out_dim(in_dim, kernel_size, stride, padding=0, output_padding=0, dilation=1):\n",
    "    return (in_dim - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + output_padding + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 17842\n",
    "\n",
    "conv_1_out_dim = conv1d_out_dim(feature_dim, 10, 3)\n",
    "maxpool_1_out_dim = maxpool1d_out_dim(conv_1_out_dim, 10, 2)\n",
    "conv_2_out_dim = conv1d_out_dim(maxpool_1_out_dim, 50, 3)\n",
    "maxpool_2_out_dim = maxpool1d_out_dim(conv_2_out_dim, 10, 2)\n",
    "\n",
    "convtranspose_1_out_dim = convtranspose1d_out_dim(maxpool_2_out_dim, 25, 3)\n",
    "upsample_1_out_dim = maxpool_1_out_dim\n",
    "convtranspose_2_out_dim = convtranspose1d_out_dim(upsample_1_out_dim, 50, 3, 0)\n",
    "upsample_2_out_dim = feature_dim\n",
    "\n",
    "print(feature_dim)\n",
    "print(conv_1_out_dim)\n",
    "print(maxpool_1_out_dim)\n",
    "print(conv_2_out_dim)\n",
    "print(maxpool_2_out_dim)\n",
    "print(convtranspose_1_out_dim)\n",
    "print(upsample_1_out_dim)\n",
    "print(convtranspose_2_out_dim)\n",
    "print(upsample_2_out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture based on: https://pythonwife.com/convolutional-autoencoders-opencv/\n",
    "\n",
    "class ConvAutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=1, kernel_size=10, stride=3),\n",
    "            nn.BatchNorm1d(num_features=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool1d(kernel_size=10, stride=2),\n",
    "            nn.Dropout(p=0.3),\n",
    "            #nn.Conv1d(in_channels=1, out_channels=1, kernel_size=25, stride=3),\n",
    "            #nn.ReLU(True),\n",
    "            #nn.MaxPool1d(kernel_size=10, stride=2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            #nn.ConvTranspose1d(in_channels=1, out_channels=1, kernel_size=25, stride=3),\n",
    "            #nn.ReLU(True),\n",
    "            #nn.Upsample(size=2961),\n",
    "            nn.ConvTranspose1d(in_channels=1, out_channels=1, kernel_size=10, stride=3),\n",
    "            nn.BatchNorm1d(num_features=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Upsample(size=17842),\n",
    "            nn.Dropout(p=0.3),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.encoder(X)\n",
    "        X = self.decoder(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_auto_encoder = ConvAutoEncoder()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(ecg_auto_encoder.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "\n",
    "total_loss = 0\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        signal, _ = data\n",
    "        signal = Variable(signal)\n",
    "\n",
    "        output = ecg_auto_encoder(signal)\n",
    "        loss = criterion(output, signal)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}: loss={total_loss}')\n",
    "    losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original with auto-encoded signal.\n",
    "num_rows = 1\n",
    "num_cols = 1\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(12 * num_cols,6 * num_rows))\n",
    "\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "sample = 30\n",
    "time_limit = 5000\n",
    "\n",
    "axs.plot(list(range(time_limit)), X_train_scaled.iloc[sample, np.r_[:time_limit]], alpha=0.5, label='Original')\n",
    "\n",
    "with torch.no_grad():\n",
    "    ecg_auto_encoder.eval()\n",
    "    signal_tensor = torch.tensor(X_train_scaled.iloc[sample].values, dtype=torch.float)\n",
    "    signal_tensor = torch.unsqueeze(signal_tensor, 0)\n",
    "    signal_tensor = torch.unsqueeze(signal_tensor, 0)\n",
    "    enc_dec_signal = ecg_auto_encoder(signal_tensor)\n",
    "    enc_dec_signal = torch.squeeze(enc_dec_signal)\n",
    "    axs.plot(list(range(time_limit)), enc_dec_signal[:time_limit], label='Reconstructed')\n",
    "axs.set(xlabel='Time', ylabel='Signal', title=f'Original vs. Reconstructed Signal No. {sample}')\n",
    "axs.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Encoded Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute encoded version of training set.\n",
    "with torch.no_grad():\n",
    "    ecg_auto_encoder.eval()\n",
    "    X_train_tensor = torch.tensor(X_train_scaled.values, dtype=torch.float)\n",
    "    X_train_tensor = torch.unsqueeze(X_train_tensor, 1)\n",
    "    X_train_enc = ecg_auto_encoder.encoder(signal_tensor)\n",
    "    X_train_enc = torch.squeeze(X_train_enc)\n",
    "    X_train_enc = pd.DataFrame(X_train_enc.numpy(), index=X_train.index)\n",
    "    display(X_train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_valid_score = cross_val_score(\n",
    "    LinearSVC(tol=1e-2),\n",
    "    X_train_enc,\n",
    "    pd.Series.ravel(y_train),\n",
    "    cv=5,\n",
    "    scoring='f1_micro',\n",
    "    verbose=4,\n",
    "    n_jobs=-1).mean()\n",
    "print(enc_valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_valid_score = cross_val_score(\n",
    "    LinearSVC(tol=1e-2),\n",
    "    X_train,\n",
    "    pd.Series.ravel(y_train),\n",
    "    cv=5,\n",
    "    scoring='f1_micro',\n",
    "    verbose=4,\n",
    "    n_jobs=-1).mean()\n",
    "print(raw_valid_score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
